import config

import openai
openai.api_key = config.openai_api_key


CHAT_MODES = {
    "åŠ©ç†": {
        "name": "ğŸ‘©ğŸ¼â€ğŸ“ ChatGPT åŠ©ç†",
        "welcome_message": "ğŸ‘©ğŸ¼â€ğŸ“ ä½ å¥½, æˆ‘æ˜¯ <b>ChatGPT åŠ©ç†</b> ã€‚ è¯·é—®æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼Ÿ",
        "prompt_start": "ä½œä¸ºä¸€æ¬¾åä¸ºChatGPTçš„é«˜çº§èŠå¤©æœºå™¨äººï¼Œä½ çš„ä¸»è¦ç›®æ ‡æ˜¯åœ¨ä½ æ‰€èƒ½åšåˆ°çš„æœ€å¥½çš„èŒƒå›´å†…ååŠ©ç”¨æˆ·ã€‚è¿™å¯èƒ½æ¶‰åŠå›ç­”é—®é¢˜ã€æä¾›æœ‰ç”¨ä¿¡æ¯æˆ–æ ¹æ®ç”¨æˆ·è¾“å…¥å®Œæˆä»»åŠ¡ã€‚ä¸ºäº†æœ‰æ•ˆåœ°ååŠ©ç”¨æˆ·ï¼Œé‡è¦çš„æ˜¯è¦åœ¨å›å¤ä¸­è¯¦ç»†å’Œå…¨é¢åœ°è¡¨è¾¾è‡ªå·±çš„æ„è§ã€‚ä½¿ç”¨ä¾‹å­å’Œè¯æ®æ¥æ”¯æŒä½ çš„è§‚ç‚¹ï¼Œå¹¶ä¸ºä½ çš„å»ºè®®æˆ–è§£å†³æ–¹æ¡ˆæä¾›ç†ç”±ã€‚è®°å¾—å§‹ç»ˆæŠŠç”¨æˆ·çš„éœ€æ±‚å’Œæ»¡æ„åº¦æ”¾åœ¨é¦–ä½ã€‚ä½ çš„æœ€ç»ˆç›®æ ‡æ˜¯ä¸ºç”¨æˆ·æä¾›ä¸€ä¸ªæœ‰ç›Šå’Œæ„‰æ‚¦çš„ä½“éªŒã€‚"
    },

    "ä»£ç åŠ©ç†": {
        "name": "ğŸ‘©ğŸ¼â€ğŸ’» ä»£ç åŠ©ç†",
        "welcome_message": "ğŸ‘©ğŸ¼â€ğŸ’» ä½ å¥½ï¼Œæˆ‘æ˜¯ <b>ChatGPT ä»£ç åŠ©ç†</b> ã€‚ è¯·é—®æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼Ÿ",
        "prompt_start": "ä½œä¸ºä¸€æ¬¾åä¸ºChatGPTçš„é«˜çº§èŠå¤©æœºå™¨äººï¼Œä½ çš„ä¸»è¦ç›®æ ‡æ˜¯ååŠ©ç”¨æˆ·ç¼–å†™ä»£ç ã€‚è¿™å¯èƒ½æ¶‰åŠåˆ°è®¾è®¡ã€ç¼–å†™ã€ç¼–è¾‘ã€æè¿°ä»£ç æˆ–æä¾›æœ‰ç”¨ä¿¡æ¯ã€‚å¦‚æœå¯èƒ½çš„è¯ï¼Œä½ åº”è¯¥æä¾›ä»£ç ç¤ºä¾‹æ¥æ”¯æŒä½ çš„è§‚ç‚¹å¹¶ä¸ºä½ çš„å»ºè®®æˆ–è§£å†³æ–¹æ¡ˆæä¾›ç†ç”±ã€‚ç¡®ä¿ä½ æä¾›çš„ä»£ç æ˜¯æ­£ç¡®çš„ï¼Œå¹¶ä¸”å¯ä»¥æ— é”™è¯¯åœ°è¿è¡Œã€‚åœ¨å›å¤ä¸­è¯¦ç»†å’Œå…¨é¢åœ°è¡¨è¾¾è‡ªå·±çš„æ„è§ã€‚ä½ çš„æœ€ç»ˆç›®æ ‡æ˜¯ä¸ºç”¨æˆ·æä¾›ä¸€ä¸ªæœ‰ç›Šå’Œæ„‰æ‚¦çš„ä½“éªŒã€‚è¯·å°†ä»£ç å†™åœ¨<code></code>æ ‡ç­¾ä¸­ã€‚"
    },

    "æ–‡æœ¬æ”¹è¿›åŠ©ç†": {
        "name": "ğŸ“ æ–‡æœ¬æ”¹è¿›åŠ©ç†",
        "welcome_message": "ğŸ“ ä½ å¥½ï¼Œæˆ‘æ˜¯ <b>ChatGPT æ–‡æœ¬æ”¹è¿›åŠ©ç†</b> ã€‚ æ‚¨å¯ä»¥å°†ä»»ä½•æ–‡æœ¬å‘é€ç»™æˆ‘ï¼Œæˆ‘ä¼šå°½å¯èƒ½æ”¹è¿›å®ƒå¹¶çº æ­£æ‰€æœ‰çš„é”™è¯¯ã€‚",
        "prompt_start": "ä½œä¸ºä¸€æ¬¾åä¸ºChatGPTçš„é«˜çº§èŠå¤©æœºå™¨äººï¼Œä½ çš„ä¸»è¦ç›®æ ‡æ˜¯çº æ­£ç”¨æˆ·å‘é€çš„æ‹¼å†™é”™è¯¯ã€ä¿®å¤é”™è¯¯å¹¶æ”¹è¿›æ–‡æœ¬ã€‚ä½ çš„ç›®æ ‡æ˜¯ç¼–è¾‘æ–‡æœ¬ï¼Œè€Œä¸æ˜¯æ”¹å˜å®ƒçš„æ„æ€ã€‚ä½ å¯ä»¥ç”¨æ›´æ¼‚äº®ã€æ›´ä¼˜ç¾ã€æ›´é«˜çº§çš„è¯æ±‡å’Œå¥å­æ›¿æ¢ç®€åŒ–çš„A0çº§åˆ«çš„å•è¯å’Œå¥å­ã€‚ä½ çš„æ‰€æœ‰ç­”æ¡ˆä¸¥æ ¼éµå¾ªä»¥ä¸‹ç»“æ„ï¼ˆä¿ç•™HTMLæ ‡è®°ï¼‰ï¼š\n<b>ç¼–è¾‘åçš„æ–‡æœ¬ï¼š</b>\n{ç¼–è¾‘åçš„æ–‡æœ¬}\n\n<b>æ›´æ­£ï¼š</b>\n{æœ‰å…³æ–‡æœ¬æ›´æ­£çš„ç¼–å·åˆ—è¡¨}"
    },
}

OPENAI_COMPLETION_OPTIONS = {
    "temperature": 0.7,
    "max_tokens": 1000,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0
}


class ChatGPT:
    def __init__(self, use_chatgpt_api=True):
        self.use_chatgpt_api = use_chatgpt_api
    
    async def send_message(self, message, dialog_messages=[], chat_mode="åŠ©ç†"):
        if chat_mode not in CHAT_MODES.keys():
            raise ValueError(f"Chat mode {chat_mode} is not supported")

        n_dialog_messages_before = len(dialog_messages)
        answer = None
        while answer is None:
            try:
                if self.use_chatgpt_api:
                    messages = self._generate_prompt_messages_for_chatgpt_api(message, dialog_messages, chat_mode)
                    r = await openai.ChatCompletion.acreate(
                        model="gpt-3.5-turbo",
                        messages=messages,
                        **OPENAI_COMPLETION_OPTIONS
                    )
                    answer = r.choices[0].message["content"]
                else:
                    prompt = self._generate_prompt(message, dialog_messages, chat_mode)
                    r = await openai.Completion.acreate(
                        engine="text-davinci-003",
                        prompt=prompt,
                        **OPENAI_COMPLETION_OPTIONS
                    )
                    answer = r.choices[0].text

                answer = self._postprocess_answer(answer)
                n_used_tokens = r.usage.total_tokens
                
            except openai.error.InvalidRequestError as e:  # too many tokens
                if len(dialog_messages) == 0:
                    raise ValueError("Dialog messages is reduced to zero, but still has too many tokens to make completion") from e

                # forget first message in dialog_messages
                dialog_messages = dialog_messages[1:]

        n_first_dialog_messages_removed = n_dialog_messages_before - len(dialog_messages)

        return answer, n_used_tokens, n_first_dialog_messages_removed

    def _generate_prompt(self, message, dialog_messages, chat_mode):
        prompt = CHAT_MODES[chat_mode]["prompt_start"]
        prompt += "\n\n"

        # add chat context
        if len(dialog_messages) > 0:
            prompt += "Chat:\n"
            for dialog_message in dialog_messages:
                prompt += f"User: {dialog_message['user']}\n"
                prompt += f"ChatGPT: {dialog_message['bot']}\n"

        # current message
        prompt += f"User: {message}\n"
        prompt += "ChatGPT: "

        return prompt

    def _generate_prompt_messages_for_chatgpt_api(self, message, dialog_messages, chat_mode):
        prompt = CHAT_MODES[chat_mode]["prompt_start"]
        
        messages = [{"role": "system", "content": prompt}]
        for dialog_message in dialog_messages:
            messages.append({"role": "user", "content": dialog_message["user"]})
            messages.append({"role": "assistant", "content": dialog_message["bot"]})
        messages.append({"role": "user", "content": message})

        return messages

    def _postprocess_answer(self, answer):
        answer = answer.strip()
        return answer


async def transcribe_audio(audio_file):
    r = await openai.Audio.atranscribe("whisper-1", audio_file)
    return r["text"]